{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNoEgsML9JijQnRk60wqLAT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sggyuan/GNN/blob/main/%E6%9C%80%E7%BB%88%EF%BC%81%EF%BC%81%EF%BC%81.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cgc3ZBqiVOXg",
        "outputId": "a30e1867-50b3-4d98-b941-8d4ca87640b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.4.0+cu121\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "print(torch.__version__)\n",
        "\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch_geometric.datasets import Planetoid\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.utils import train_test_split_edges\n",
        "import torch.nn as nn\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch_geometric.nn import GAE\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "k5u3fUQ8VO4h"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Rurk_GEVTVN",
        "outputId": "172b70bf-2805-4d0d-8235-27764e113250"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = torch.load('/content/drive/MyDrive/my_graph_data-bal.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAJ2IELHVVKd",
        "outputId": "509cd80e-e7d0-45ad-9140-44ea9ea1234c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-e9945f3ad513>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  data = torch.load('/content/drive/MyDrive/my_graph_data-bal.pt')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = train_test_split_edges(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQeOOiw8WMNM",
        "outputId": "c6ef35a5-b59d-49a0-b53d-d3552c7060e9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'train_test_split_edges' is deprecated, use 'transforms.RandomLinkSplit' instead\n",
            "  warnings.warn(out)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvF4ORTNWOGk",
        "outputId": "dd50eace-c00e-4a82-935b-d1849f4f2911"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Data(x=[16283, 13], y=[100000], val_pos_edge_index=[2, 5000], val_pos_edge_attr=[5000, 8], test_pos_edge_index=[2, 10000], test_pos_edge_attr=[10000, 8], train_pos_edge_index=[2, 99256], train_pos_edge_attr=[99256, 8], train_neg_adj_mask=[16283, 16283], val_neg_edge_index=[2, 5000], test_neg_edge_index=[2, 10000])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GCNEncoder(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, hidden_channels=64):\n",
        "        super(GCNEncoder, self).__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.conv3 = GCNConv(hidden_channels, out_channels)\n",
        "\n",
        "        self.bn1 = nn.BatchNorm1d(hidden_channels)\n",
        "        self.bn2 = nn.BatchNorm1d(hidden_channels)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        # First GCN layer\n",
        "        x1 = F.leaky_relu(self.bn1(self.conv1(x, edge_index)))\n",
        "        x1 = self.dropout(x1)\n",
        "\n",
        "        # Second GCN layer with residual connection\n",
        "        x2 = F.leaky_relu(self.bn2(self.conv2(x1, edge_index))) + x1\n",
        "        x2 = self.dropout(x2)\n",
        "\n",
        "        # Final GCN layer\n",
        "        x3 = self.conv3(x2, edge_index)\n",
        "\n",
        "        return x3\n",
        ""
      ],
      "metadata": {
        "id": "ih7yCyFOVWqF"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out_channels = 2\n",
        "num_features = data.num_features\n",
        "epochs = 100\n",
        "\n",
        "model1 = GAE(GCNEncoder(num_features, out_channels))\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model1 = model1.to(device)\n",
        "x = data.x.to(device)\n",
        "train_pos_edge_index = data.train_pos_edge_index.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model1.parameters(), lr=0.001, weight_decay=5e-4)\n",
        "scheduler = ReduceLROnPlateau(optimizer, 'max', patience=10, factor=0.5)\n"
      ],
      "metadata": {
        "id": "GSavA8fqVu71"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    z = model1.encode(x, train_pos_edge_index)\n",
        "    loss = model1.recon_loss(z, train_pos_edge_index)\n",
        "    #if args.variational:\n",
        "    #   loss = loss + (1 / data.num_nodes) * model.kl_loss()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return float(loss)\n",
        "\n",
        "\n",
        "def test(pos_edge_index, neg_edge_index):\n",
        "    model1.eval()\n",
        "    with torch.no_grad():\n",
        "        z = model1.encode(x, train_pos_edge_index)\n",
        "    return model1.test(z, pos_edge_index, neg_edge_index)"
      ],
      "metadata": {
        "id": "k77XdDuVWEcK"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import division\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_scatter import scatter_add\n",
        "\n",
        "\n",
        "def true_positive(pred, target, num_classes):\n",
        "    r\"\"\"Computes the number of true positive predictions.\n",
        "\n",
        "    Args:\n",
        "        pred (Tensor): The predictions.\n",
        "        target (Tensor): The targets.\n",
        "        num_classes (int): The number of classes.\n",
        "\n",
        "    :rtype: :class:`LongTensor`\n",
        "    \"\"\"\n",
        "    out = []\n",
        "    for i in range(num_classes):\n",
        "        out.append(((pred == i) & (target == i)).sum())\n",
        "\n",
        "    return torch.tensor(out)\n",
        "\n",
        "\n",
        "\n",
        "def true_negative(pred, target, num_classes):\n",
        "    r\"\"\"Computes the number of true negative predictions.\n",
        "\n",
        "    Args:\n",
        "        pred (Tensor): The predictions.\n",
        "        target (Tensor): The targets.\n",
        "        num_classes (int): The number of classes.\n",
        "\n",
        "    :rtype: :class:`LongTensor`\n",
        "    \"\"\"\n",
        "    out = []\n",
        "    for i in range(num_classes):\n",
        "        out.append(((pred != i) & (target != i)).sum())\n",
        "\n",
        "    return torch.tensor(out)\n",
        "\n",
        "\n",
        "\n",
        "def false_positive(pred, target, num_classes):\n",
        "    r\"\"\"Computes the number of false positive predictions.\n",
        "\n",
        "    Args:\n",
        "        pred (Tensor): The predictions.\n",
        "        target (Tensor): The targets.\n",
        "        num_classes (int): The number of classes.\n",
        "\n",
        "    :rtype: :class:`LongTensor`\n",
        "    \"\"\"\n",
        "    out = []\n",
        "    for i in range(num_classes):\n",
        "        out.append(((pred == i) & (target != i)).sum())\n",
        "\n",
        "    return torch.tensor(out)\n",
        "\n",
        "\n",
        "def false_negative(pred, target, num_classes):\n",
        "    r\"\"\"Computes the number of false negative predictions.\n",
        "\n",
        "    Args:\n",
        "        pred (Tensor): The predictions.\n",
        "        target (Tensor): The targets.\n",
        "        num_classes (int): The number of classes.\n",
        "\n",
        "    :rtype: :class:`LongTensor`\n",
        "    \"\"\"\n",
        "    out = []\n",
        "    for i in range(num_classes):\n",
        "        out.append(((pred != i) & (target == i)).sum())\n",
        "\n",
        "    return torch.tensor(out)\n",
        "\n",
        "\n",
        "def recall(pred, target, num_classes):\n",
        "    r\"\"\"Computes the recall\n",
        "    :math:`\\frac{\\mathrm{TP}}{\\mathrm{TP}+\\mathrm{FN}}` of predictions.\n",
        "\n",
        "    Args:\n",
        "        pred (Tensor): The predictions.\n",
        "        target (Tensor): The targets.\n",
        "        num_classes (int): The number of classes.\n",
        "\n",
        "    :rtype: :class:`Tensor`\n",
        "    \"\"\"\n",
        "    tp = true_positive(pred, target, num_classes).to(torch.float)\n",
        "    fn = false_negative(pred, target, num_classes).to(torch.float)\n",
        "\n",
        "    out = tp / (tp + fn)\n",
        "    out[torch.isnan(out)] = 0\n",
        "\n",
        "    return out\n",
        "\n",
        "\n",
        "\n",
        "def f1_score(pred, target, num_classes):\n",
        "    r\"\"\"Computes the :math:`F_1` score\n",
        "    :math:`2 \\cdot \\frac{\\mathrm{precision} \\cdot \\mathrm{recall}}\n",
        "    {\\mathrm{precision}+\\mathrm{recall}}` of predictions.\n",
        "\n",
        "    Args:\n",
        "        pred (Tensor): The predictions.\n",
        "        target (Tensor): The targets.\n",
        "        num_classes (int): The number of classes.\n",
        "\n",
        "    :rtype: :class:`Tensor`\n",
        "    \"\"\"\n",
        "    prec = precision(pred, target, num_classes)\n",
        "    rec = recall(pred, target, num_classes)\n",
        "\n",
        "    score = 2 * (prec * rec) / (prec + rec)\n",
        "    score[torch.isnan(score)] = 0\n",
        "\n",
        "    return score"
      ],
      "metadata": {
        "id": "ACnZRxzii_Q2"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(pos_edge_index, neg_edge_index):\n",
        "    model1.eval()\n",
        "    with torch.no_grad():\n",
        "        z = model1.encode(x, train_pos_edge_index)\n",
        "        pos_out = model1.decode(z, pos_edge_index)\n",
        "        neg_out = model1.decode(z, neg_edge_index)\n",
        "\n",
        "        pred_scores = torch.cat([pos_out, neg_out], dim=0)\n",
        "\n",
        "        # 创建真实标签\n",
        "        y_true = torch.cat([torch.ones(pos_out.size(0)), torch.zeros(neg_out.size(0))], dim=0)\n",
        "\n",
        "        # 确保 pred_scores 和 y_true 在同一设备上\n",
        "        pred_scores = pred_scores.cpu()\n",
        "        y_true = y_true.cpu()\n",
        "\n",
        "        # 将预测分数转换为二进制预测\n",
        "        y_pred = (pred_scores > 0.5).long()\n",
        "\n",
        "        # 计算 AUC 和 AP\n",
        "        auc = roc_auc_score(y_true.numpy(), pred_scores.numpy())\n",
        "        ap = average_precision_score(y_true.numpy(), pred_scores.numpy())\n",
        "\n",
        "        # 计算 Recall 和 F1 分数\n",
        "        num_classes = 2  # 因为这是二分类问题\n",
        "        rec = recall(y_pred, y_true, num_classes)[1]  # 只取正类的召回率\n",
        "        f1 = f1_score(y_pred, y_true, num_classes)[1]  # 只取正类的 F1 分数\n",
        "\n",
        "    return auc, ap, rec.item(), f1.item()\n",
        "\n",
        "# 在主循环中使用\n",
        "for epoch in range(1, epochs + 1):\n",
        "    loss = train()\n",
        "    auc, ap, rec, f1 = test(data.test_pos_edge_index, data.test_neg_edge_index)\n",
        "    print(f'Epoch: {epoch:03d}, AUC: {auc:.4f}, AP: {ap:.4f}, '\n",
        "          f'Recall: {rec:.4f}, F1: {f1:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HP_rQ9iRj_dS",
        "outputId": "36565fd4-883a-4058-f6b0-9c3bca3c5a0e"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 001, AUC: 0.8784, AP: 0.9197, Recall: 0.9075, F1: 0.7176\n",
            "Epoch: 002, AUC: 0.8786, AP: 0.9199, Recall: 0.9080, F1: 0.7167\n",
            "Epoch: 003, AUC: 0.8783, AP: 0.9198, Recall: 0.9071, F1: 0.7185\n",
            "Epoch: 004, AUC: 0.8784, AP: 0.9199, Recall: 0.9074, F1: 0.7185\n",
            "Epoch: 005, AUC: 0.8784, AP: 0.9200, Recall: 0.9080, F1: 0.7188\n",
            "Epoch: 006, AUC: 0.8783, AP: 0.9200, Recall: 0.9077, F1: 0.7195\n",
            "Epoch: 007, AUC: 0.8780, AP: 0.9198, Recall: 0.9067, F1: 0.7207\n",
            "Epoch: 008, AUC: 0.8776, AP: 0.9197, Recall: 0.9061, F1: 0.7216\n",
            "Epoch: 009, AUC: 0.8771, AP: 0.9194, Recall: 0.9046, F1: 0.7232\n",
            "Epoch: 010, AUC: 0.8766, AP: 0.9192, Recall: 0.9033, F1: 0.7243\n",
            "Epoch: 011, AUC: 0.8767, AP: 0.9192, Recall: 0.9037, F1: 0.7238\n",
            "Epoch: 012, AUC: 0.8766, AP: 0.9192, Recall: 0.9035, F1: 0.7241\n",
            "Epoch: 013, AUC: 0.8771, AP: 0.9195, Recall: 0.9045, F1: 0.7228\n",
            "Epoch: 014, AUC: 0.8776, AP: 0.9197, Recall: 0.9055, F1: 0.7218\n",
            "Epoch: 015, AUC: 0.8778, AP: 0.9198, Recall: 0.9058, F1: 0.7209\n",
            "Epoch: 016, AUC: 0.8782, AP: 0.9200, Recall: 0.9067, F1: 0.7171\n",
            "Epoch: 017, AUC: 0.8778, AP: 0.9196, Recall: 0.9064, F1: 0.7168\n",
            "Epoch: 018, AUC: 0.8776, AP: 0.9194, Recall: 0.9064, F1: 0.7156\n",
            "Epoch: 019, AUC: 0.8778, AP: 0.9193, Recall: 0.9077, F1: 0.7155\n",
            "Epoch: 020, AUC: 0.8782, AP: 0.9195, Recall: 0.9087, F1: 0.7141\n",
            "Epoch: 021, AUC: 0.8786, AP: 0.9197, Recall: 0.9092, F1: 0.7131\n",
            "Epoch: 022, AUC: 0.8790, AP: 0.9199, Recall: 0.9099, F1: 0.7125\n",
            "Epoch: 023, AUC: 0.8794, AP: 0.9202, Recall: 0.9105, F1: 0.7113\n",
            "Epoch: 024, AUC: 0.8795, AP: 0.9204, Recall: 0.9096, F1: 0.7120\n",
            "Epoch: 025, AUC: 0.8797, AP: 0.9206, Recall: 0.9099, F1: 0.7140\n",
            "Epoch: 026, AUC: 0.8794, AP: 0.9206, Recall: 0.9090, F1: 0.7157\n",
            "Epoch: 027, AUC: 0.8788, AP: 0.9203, Recall: 0.9085, F1: 0.7190\n",
            "Epoch: 028, AUC: 0.8781, AP: 0.9200, Recall: 0.9072, F1: 0.7214\n",
            "Epoch: 029, AUC: 0.8779, AP: 0.9199, Recall: 0.9068, F1: 0.7210\n",
            "Epoch: 030, AUC: 0.8781, AP: 0.9201, Recall: 0.9073, F1: 0.7203\n",
            "Epoch: 031, AUC: 0.8781, AP: 0.9201, Recall: 0.9072, F1: 0.7199\n",
            "Epoch: 032, AUC: 0.8779, AP: 0.9200, Recall: 0.9069, F1: 0.7206\n",
            "Epoch: 033, AUC: 0.8783, AP: 0.9202, Recall: 0.9076, F1: 0.7197\n",
            "Epoch: 034, AUC: 0.8790, AP: 0.9205, Recall: 0.9088, F1: 0.7183\n",
            "Epoch: 035, AUC: 0.8792, AP: 0.9206, Recall: 0.9095, F1: 0.7179\n",
            "Epoch: 036, AUC: 0.8798, AP: 0.9209, Recall: 0.9105, F1: 0.7162\n",
            "Epoch: 037, AUC: 0.8799, AP: 0.9210, Recall: 0.9103, F1: 0.7148\n",
            "Epoch: 038, AUC: 0.8806, AP: 0.9213, Recall: 0.9116, F1: 0.7136\n",
            "Epoch: 039, AUC: 0.8807, AP: 0.9214, Recall: 0.9117, F1: 0.7137\n",
            "Epoch: 040, AUC: 0.8813, AP: 0.9217, Recall: 0.9135, F1: 0.7121\n",
            "Epoch: 041, AUC: 0.8812, AP: 0.9216, Recall: 0.9123, F1: 0.7120\n",
            "Epoch: 042, AUC: 0.8812, AP: 0.9215, Recall: 0.9121, F1: 0.7115\n",
            "Epoch: 043, AUC: 0.8807, AP: 0.9212, Recall: 0.9117, F1: 0.7133\n",
            "Epoch: 044, AUC: 0.8807, AP: 0.9212, Recall: 0.9118, F1: 0.7128\n",
            "Epoch: 045, AUC: 0.8806, AP: 0.9211, Recall: 0.9118, F1: 0.7129\n",
            "Epoch: 046, AUC: 0.8804, AP: 0.9210, Recall: 0.9115, F1: 0.7133\n",
            "Epoch: 047, AUC: 0.8801, AP: 0.9209, Recall: 0.9111, F1: 0.7148\n",
            "Epoch: 048, AUC: 0.8796, AP: 0.9206, Recall: 0.9095, F1: 0.7167\n",
            "Epoch: 049, AUC: 0.8792, AP: 0.9205, Recall: 0.9088, F1: 0.7175\n",
            "Epoch: 050, AUC: 0.8788, AP: 0.9203, Recall: 0.9078, F1: 0.7192\n",
            "Epoch: 051, AUC: 0.8784, AP: 0.9201, Recall: 0.9070, F1: 0.7208\n",
            "Epoch: 052, AUC: 0.8780, AP: 0.9199, Recall: 0.9061, F1: 0.7224\n",
            "Epoch: 053, AUC: 0.8770, AP: 0.9194, Recall: 0.9042, F1: 0.7244\n",
            "Epoch: 054, AUC: 0.8766, AP: 0.9193, Recall: 0.9030, F1: 0.7253\n",
            "Epoch: 055, AUC: 0.8763, AP: 0.9191, Recall: 0.9015, F1: 0.7251\n",
            "Epoch: 056, AUC: 0.8763, AP: 0.9191, Recall: 0.9016, F1: 0.7252\n",
            "Epoch: 057, AUC: 0.8758, AP: 0.9189, Recall: 0.9005, F1: 0.7255\n",
            "Epoch: 058, AUC: 0.8758, AP: 0.9189, Recall: 0.9007, F1: 0.7257\n",
            "Epoch: 059, AUC: 0.8755, AP: 0.9187, Recall: 0.9002, F1: 0.7259\n",
            "Epoch: 060, AUC: 0.8757, AP: 0.9188, Recall: 0.9010, F1: 0.7249\n",
            "Epoch: 061, AUC: 0.8763, AP: 0.9191, Recall: 0.9016, F1: 0.7233\n",
            "Epoch: 062, AUC: 0.8764, AP: 0.9191, Recall: 0.9020, F1: 0.7229\n",
            "Epoch: 063, AUC: 0.8766, AP: 0.9192, Recall: 0.9032, F1: 0.7230\n",
            "Epoch: 064, AUC: 0.8771, AP: 0.9195, Recall: 0.9048, F1: 0.7216\n",
            "Epoch: 065, AUC: 0.8772, AP: 0.9195, Recall: 0.9048, F1: 0.7207\n",
            "Epoch: 066, AUC: 0.8775, AP: 0.9197, Recall: 0.9054, F1: 0.7210\n",
            "Epoch: 067, AUC: 0.8774, AP: 0.9196, Recall: 0.9048, F1: 0.7224\n",
            "Epoch: 068, AUC: 0.8778, AP: 0.9198, Recall: 0.9056, F1: 0.7231\n",
            "Epoch: 069, AUC: 0.8780, AP: 0.9200, Recall: 0.9058, F1: 0.7233\n",
            "Epoch: 070, AUC: 0.8782, AP: 0.9201, Recall: 0.9061, F1: 0.7239\n",
            "Epoch: 071, AUC: 0.8781, AP: 0.9201, Recall: 0.9059, F1: 0.7245\n",
            "Epoch: 072, AUC: 0.8782, AP: 0.9201, Recall: 0.9062, F1: 0.7247\n",
            "Epoch: 073, AUC: 0.8784, AP: 0.9202, Recall: 0.9065, F1: 0.7246\n",
            "Epoch: 074, AUC: 0.8785, AP: 0.9203, Recall: 0.9065, F1: 0.7244\n",
            "Epoch: 075, AUC: 0.8785, AP: 0.9203, Recall: 0.9065, F1: 0.7240\n",
            "Epoch: 076, AUC: 0.8785, AP: 0.9203, Recall: 0.9065, F1: 0.7239\n",
            "Epoch: 077, AUC: 0.8786, AP: 0.9204, Recall: 0.9069, F1: 0.7240\n",
            "Epoch: 078, AUC: 0.8785, AP: 0.9204, Recall: 0.9066, F1: 0.7236\n",
            "Epoch: 079, AUC: 0.8784, AP: 0.9203, Recall: 0.9060, F1: 0.7238\n",
            "Epoch: 080, AUC: 0.8787, AP: 0.9204, Recall: 0.9067, F1: 0.7233\n",
            "Epoch: 081, AUC: 0.8784, AP: 0.9203, Recall: 0.9059, F1: 0.7239\n",
            "Epoch: 082, AUC: 0.8784, AP: 0.9203, Recall: 0.9058, F1: 0.7240\n",
            "Epoch: 083, AUC: 0.8783, AP: 0.9202, Recall: 0.9058, F1: 0.7246\n",
            "Epoch: 084, AUC: 0.8788, AP: 0.9205, Recall: 0.9069, F1: 0.7233\n",
            "Epoch: 085, AUC: 0.8786, AP: 0.9204, Recall: 0.9065, F1: 0.7237\n",
            "Epoch: 086, AUC: 0.8784, AP: 0.9204, Recall: 0.9061, F1: 0.7241\n",
            "Epoch: 087, AUC: 0.8788, AP: 0.9206, Recall: 0.9071, F1: 0.7236\n",
            "Epoch: 088, AUC: 0.8792, AP: 0.9208, Recall: 0.9081, F1: 0.7225\n",
            "Epoch: 089, AUC: 0.8798, AP: 0.9212, Recall: 0.9089, F1: 0.7205\n",
            "Epoch: 090, AUC: 0.8799, AP: 0.9212, Recall: 0.9089, F1: 0.7201\n",
            "Epoch: 091, AUC: 0.8800, AP: 0.9212, Recall: 0.9092, F1: 0.7194\n",
            "Epoch: 092, AUC: 0.8802, AP: 0.9213, Recall: 0.9098, F1: 0.7186\n",
            "Epoch: 093, AUC: 0.8805, AP: 0.9214, Recall: 0.9105, F1: 0.7164\n",
            "Epoch: 094, AUC: 0.8807, AP: 0.9216, Recall: 0.9112, F1: 0.7145\n",
            "Epoch: 095, AUC: 0.8807, AP: 0.9215, Recall: 0.9112, F1: 0.7153\n",
            "Epoch: 096, AUC: 0.8803, AP: 0.9214, Recall: 0.9102, F1: 0.7158\n",
            "Epoch: 097, AUC: 0.8802, AP: 0.9213, Recall: 0.9101, F1: 0.7161\n",
            "Epoch: 098, AUC: 0.8801, AP: 0.9213, Recall: 0.9102, F1: 0.7173\n",
            "Epoch: 099, AUC: 0.8798, AP: 0.9211, Recall: 0.9088, F1: 0.7196\n",
            "Epoch: 100, AUC: 0.8794, AP: 0.9209, Recall: 0.9081, F1: 0.7212\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m-UC4G63m7fe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0I29Ehp0XZC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fzTgSOGtYDaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LIv1bW-eYDcO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.nn import VGAE"
      ],
      "metadata": {
        "id": "DzTL9uiNYDeZ"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "\n",
        "class VariationalGCNEncoder(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, hidden_channels=64):\n",
        "        super(VariationalGCNEncoder, self).__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.conv_mu = GCNConv(hidden_channels, out_channels)\n",
        "        self.conv_logstd = GCNConv(hidden_channels, out_channels)\n",
        "\n",
        "        self.bn1 = nn.BatchNorm1d(hidden_channels)\n",
        "        self.bn2 = nn.BatchNorm1d(hidden_channels)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        # First GCN layer\n",
        "        x1 = F.leaky_relu(self.bn1(self.conv1(x, edge_index)))\n",
        "        x1 = self.dropout(x1)\n",
        "\n",
        "        # Second GCN layer with residual connection\n",
        "        x2 = F.leaky_relu(self.bn2(self.conv2(x1, edge_index))) + x1\n",
        "        x2 = self.dropout(x2)\n",
        "\n",
        "        # Final GCN layers for mean and log-standard deviation\n",
        "        mu = self.conv_mu(x2, edge_index)\n",
        "        logstd = self.conv_logstd(x2, edge_index)\n",
        "\n",
        "        return mu, logstd\n",
        "\n",
        "    def reparameterize(self, mu, logstd):\n",
        "        if self.training:\n",
        "            return mu + torch.randn_like(logstd) * torch.exp(logstd)\n",
        "        else:\n",
        "            return mu"
      ],
      "metadata": {
        "id": "2lBpHRenFSOV"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out_channels = 2\n",
        "num_features = data.num_features\n",
        "epochs = 300\n",
        "\n",
        "\n",
        "model2 = VGAE(VariationalGCNEncoder(num_features, out_channels))  # new line\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model2 = model2.to(device)\n",
        "x = data.x.to(device)\n",
        "train_pos_edge_index = data.train_pos_edge_index.to(device)\n",
        "optimizer = torch.optim.Adam(model2.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "scheduler = ReduceLROnPlateau(optimizer, 'max', patience=10, factor=0.5)"
      ],
      "metadata": {
        "id": "YCFTdLCPENj0"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "    model2.train()\n",
        "    optimizer.zero_grad()\n",
        "    z = model2.encode(x, train_pos_edge_index)\n",
        "    loss = model2.recon_loss(z, train_pos_edge_index)\n",
        "\n",
        "    loss = loss + (1 / data.num_nodes) * model2.kl_loss()  # new line\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return float(loss)\n",
        "\n",
        "\n",
        "def test(pos_edge_index, neg_edge_index):\n",
        "    model2.eval()\n",
        "    with torch.no_grad():\n",
        "        z = model2.encode(x, train_pos_edge_index)\n",
        "    return model2.test(z, pos_edge_index, neg_edge_index)"
      ],
      "metadata": {
        "id": "fGPMMxaxHPTz"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "    model2.train()\n",
        "    optimizer.zero_grad()\n",
        "    z = model2.encode(x, train_pos_edge_index)\n",
        "    loss = model2.recon_loss(z, train_pos_edge_index)\n",
        "\n",
        "    loss = loss + (1 / data.num_nodes) * model2.kl_loss()  # new line\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return float(loss)\n",
        "\n",
        "def test(pos_edge_index, neg_edge_index):\n",
        "    model2.eval()\n",
        "    with torch.no_grad():\n",
        "        z = model2.encode(x, train_pos_edge_index)\n",
        "        pos_out = model2.decode(z, pos_edge_index)\n",
        "        neg_out = model2.decode(z, neg_edge_index)\n",
        "\n",
        "        pred_scores = torch.cat([pos_out, neg_out], dim=0)\n",
        "        y_true = torch.cat([torch.ones(pos_out.size(0)), torch.zeros(neg_out.size(0))], dim=0)\n",
        "\n",
        "        pred_scores = pred_scores.cpu()\n",
        "        y_true = y_true.cpu()\n",
        "\n",
        "        y_pred = (pred_scores > 0.5).long()\n",
        "\n",
        "        auc = roc_auc_score(y_true.numpy(), pred_scores.numpy())\n",
        "        ap = average_precision_score(y_true.numpy(), pred_scores.numpy())\n",
        "\n",
        "        num_classes = 2\n",
        "        rec = recall(y_pred, y_true, num_classes)[1]\n",
        "        f1 = f1_score(y_pred, y_true, num_classes)[1]\n",
        "\n",
        "    return auc, ap, rec.item(), f1.item()\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    loss = train()\n",
        "    auc, ap, rec, f1 = test(data.test_pos_edge_index, data.test_neg_edge_index)\n",
        "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, AUC: {auc:.4f}, AP: {ap:.4f}, '\n",
        "          f'Recall: {rec:.4f}, F1: {f1:.4f}')"
      ],
      "metadata": {
        "id": "7maOC-tZezj0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7dEVUfaWc-8L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}