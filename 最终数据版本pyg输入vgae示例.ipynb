{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPg9rWjYbQOx7nfehCYrC/0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sggyuan/GNN/blob/main/%E6%9C%80%E7%BB%88%E6%95%B0%E6%8D%AE%E7%89%88%E6%9C%ACpyg%E8%BE%93%E5%85%A5vgae%E7%A4%BA%E4%BE%8B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSo9g_umDeqa",
        "outputId": "b6bde5ee-00fa-4a70-ab66-c87061d3f5a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.4.0+cu121\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "print(torch.__version__)\n",
        "\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch_geometric.datasets import Planetoid\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.utils import train_test_split_edges"
      ],
      "metadata": {
        "id": "AgJ6pjzJDfOT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kC5BDiQ6Dvl5",
        "outputId": "b72f6e25-936e-4457-c557-847bd69f0c34"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = torch.load('/content/drive/MyDrive/my_graph_data-4.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "taY3ru3pF-AM",
        "outputId": "8442fdbc-20cc-45a3-d250-62e08e339ec7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-737c7aca6486>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  data = torch.load('/content/drive/MyDrive/my_graph_data-4.pt')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.train_mask = data.val_mask = data.test_mask = None\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oq-iTVLLGTrz",
        "outputId": "76e86bd5-9526-451c-eaae-e630e44e8c62"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Data(x=[11241, 20], edge_index=[2, 80252], y=[11241])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = train_test_split_edges(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoF_vYeBGXwb",
        "outputId": "c2b7fbba-da77-401b-8a00-651307126f83"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'train_test_split_edges' is deprecated, use 'transforms.RandomLinkSplit' instead\n",
            "  warnings.warn(out)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_0nwNkxGals",
        "outputId": "bbcf034e-ed10-49e1-8bf7-209f6bae9d1f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Data(x=[11241, 20], y=[11241], val_pos_edge_index=[2, 2006], test_pos_edge_index=[2, 4012], train_pos_edge_index=[2, 68214], train_neg_adj_mask=[11241, 11241], val_neg_edge_index=[2, 2006], test_neg_edge_index=[2, 4012])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GCNEncoder(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(GCNEncoder, self).__init__()\n",
        "        self.conv1 = GCNConv(in_channels, 2 * out_channels, cached=True) # cached only for transductive learning\n",
        "        self.conv2 = GCNConv(2 * out_channels, out_channels, cached=True) # cached only for transductive learning\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index).relu()\n",
        "        return self.conv2(x, edge_index)\n",
        ""
      ],
      "metadata": {
        "id": "VjgbD_CmGfd-"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.nn import GAE"
      ],
      "metadata": {
        "id": "lLeVBLbCGi2r"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "# parameters\n",
        "out_channels = 2\n",
        "num_features = data.num_features\n",
        "epochs = 100\n",
        "\n",
        "# model\n",
        "model = GAE(GCNEncoder(num_features, out_channels))\n",
        "\n",
        "# move to GPU (if available)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "x = data.x.to(device)\n",
        "train_pos_edge_index = data.train_pos_edge_index.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "scheduler = ReduceLROnPlateau(optimizer, 'max', patience=10, factor=0.5)"
      ],
      "metadata": {
        "id": "vRm6EOv0Gknx"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    z = model.encode(x, train_pos_edge_index)\n",
        "    loss = model.recon_loss(z, train_pos_edge_index)\n",
        "    #if args.variational:\n",
        "    #   loss = loss + (1 / data.num_nodes) * model.kl_loss()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return float(loss)\n",
        "\n",
        "\n",
        "def test(pos_edge_index, neg_edge_index):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        z = model.encode(x, train_pos_edge_index)\n",
        "    return model.test(z, pos_edge_index, neg_edge_index)"
      ],
      "metadata": {
        "id": "EBEUWe7IGmZY"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, epochs + 1):\n",
        "    loss = train()\n",
        "\n",
        "    auc, ap = test(data.test_pos_edge_index, data.test_neg_edge_index)\n",
        "    print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2128hr4Guj5",
        "outputId": "183e3e97-d63a-46aa-dedc-c6d0b791fa4f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 001, AUC: 0.5000, AP: 0.5000\n",
            "Epoch: 002, AUC: 0.5000, AP: 0.5000\n",
            "Epoch: 003, AUC: 0.5000, AP: 0.5000\n",
            "Epoch: 004, AUC: 0.5000, AP: 0.5000\n",
            "Epoch: 005, AUC: 0.5000, AP: 0.5000\n",
            "Epoch: 006, AUC: 0.5000, AP: 0.5000\n",
            "Epoch: 007, AUC: 0.5000, AP: 0.5000\n",
            "Epoch: 008, AUC: 0.5000, AP: 0.5000\n",
            "Epoch: 009, AUC: 0.5000, AP: 0.5000\n",
            "Epoch: 010, AUC: 0.5000, AP: 0.5000\n",
            "Epoch: 011, AUC: 0.5000, AP: 0.5000\n",
            "Epoch: 012, AUC: 0.5000, AP: 0.5000\n",
            "Epoch: 013, AUC: 0.5001, AP: 0.5001\n",
            "Epoch: 014, AUC: 0.5002, AP: 0.5001\n",
            "Epoch: 015, AUC: 0.5002, AP: 0.5001\n",
            "Epoch: 016, AUC: 0.5004, AP: 0.5002\n",
            "Epoch: 017, AUC: 0.5004, AP: 0.5002\n",
            "Epoch: 018, AUC: 0.5004, AP: 0.5002\n",
            "Epoch: 019, AUC: 0.5004, AP: 0.5002\n",
            "Epoch: 020, AUC: 0.5004, AP: 0.5002\n",
            "Epoch: 021, AUC: 0.5004, AP: 0.5002\n",
            "Epoch: 022, AUC: 0.5004, AP: 0.5002\n",
            "Epoch: 023, AUC: 0.5004, AP: 0.5002\n",
            "Epoch: 024, AUC: 0.5004, AP: 0.5002\n",
            "Epoch: 025, AUC: 0.5004, AP: 0.5002\n",
            "Epoch: 026, AUC: 0.5004, AP: 0.5002\n",
            "Epoch: 027, AUC: 0.5004, AP: 0.5002\n",
            "Epoch: 028, AUC: 0.5004, AP: 0.5002\n",
            "Epoch: 029, AUC: 0.5002, AP: 0.5001\n",
            "Epoch: 030, AUC: 0.5001, AP: 0.5001\n",
            "Epoch: 031, AUC: 0.5004, AP: 0.5002\n",
            "Epoch: 032, AUC: 0.5010, AP: 0.5005\n",
            "Epoch: 033, AUC: 0.5017, AP: 0.5009\n",
            "Epoch: 034, AUC: 0.5021, AP: 0.5011\n",
            "Epoch: 035, AUC: 0.5031, AP: 0.5016\n",
            "Epoch: 036, AUC: 0.5041, AP: 0.5021\n",
            "Epoch: 037, AUC: 0.5065, AP: 0.5033\n",
            "Epoch: 038, AUC: 0.5093, AP: 0.5048\n",
            "Epoch: 039, AUC: 0.5099, AP: 0.5058\n",
            "Epoch: 040, AUC: 0.5051, AP: 0.5041\n",
            "Epoch: 041, AUC: 0.5274, AP: 0.5170\n",
            "Epoch: 042, AUC: 0.5873, AP: 0.5556\n",
            "Epoch: 043, AUC: 0.2452, AP: 0.4599\n",
            "Epoch: 044, AUC: 0.3697, AP: 0.4661\n",
            "Epoch: 045, AUC: 0.5948, AP: 0.5597\n",
            "Epoch: 046, AUC: 0.5799, AP: 0.5487\n",
            "Epoch: 047, AUC: 0.5659, AP: 0.5395\n",
            "Epoch: 048, AUC: 0.5617, AP: 0.5368\n",
            "Epoch: 049, AUC: 0.5594, AP: 0.5352\n",
            "Epoch: 050, AUC: 0.5595, AP: 0.5352\n",
            "Epoch: 051, AUC: 0.5600, AP: 0.5355\n",
            "Epoch: 052, AUC: 0.5588, AP: 0.5347\n",
            "Epoch: 053, AUC: 0.5592, AP: 0.5350\n",
            "Epoch: 054, AUC: 0.5614, AP: 0.5364\n",
            "Epoch: 055, AUC: 0.5638, AP: 0.5379\n",
            "Epoch: 056, AUC: 0.5723, AP: 0.5434\n",
            "Epoch: 057, AUC: 0.5787, AP: 0.5475\n",
            "Epoch: 058, AUC: 0.5817, AP: 0.5494\n",
            "Epoch: 059, AUC: 0.5846, AP: 0.5514\n",
            "Epoch: 060, AUC: 0.5879, AP: 0.5535\n",
            "Epoch: 061, AUC: 0.5920, AP: 0.5566\n",
            "Epoch: 062, AUC: 0.5949, AP: 0.5588\n",
            "Epoch: 063, AUC: 0.5928, AP: 0.5584\n",
            "Epoch: 064, AUC: 0.5870, AP: 0.5553\n",
            "Epoch: 065, AUC: 0.5711, AP: 0.5461\n",
            "Epoch: 066, AUC: 0.4954, AP: 0.5067\n",
            "Epoch: 067, AUC: 0.4997, AP: 0.5083\n",
            "Epoch: 068, AUC: 0.4998, AP: 0.5083\n",
            "Epoch: 069, AUC: 0.4662, AP: 0.4939\n",
            "Epoch: 070, AUC: 0.4055, AP: 0.4703\n",
            "Epoch: 071, AUC: 0.3552, AP: 0.4594\n",
            "Epoch: 072, AUC: 0.3424, AP: 0.4568\n",
            "Epoch: 073, AUC: 0.5975, AP: 0.5619\n",
            "Epoch: 074, AUC: 0.5875, AP: 0.5535\n",
            "Epoch: 075, AUC: 0.5713, AP: 0.5429\n",
            "Epoch: 076, AUC: 0.5537, AP: 0.5318\n",
            "Epoch: 077, AUC: 0.5398, AP: 0.5236\n",
            "Epoch: 078, AUC: 0.5303, AP: 0.5181\n",
            "Epoch: 079, AUC: 0.5257, AP: 0.5154\n",
            "Epoch: 080, AUC: 0.5207, AP: 0.5126\n",
            "Epoch: 081, AUC: 0.5177, AP: 0.5109\n",
            "Epoch: 082, AUC: 0.5150, AP: 0.5094\n",
            "Epoch: 083, AUC: 0.5120, AP: 0.5078\n",
            "Epoch: 084, AUC: 0.5090, AP: 0.5060\n",
            "Epoch: 085, AUC: 0.5081, AP: 0.5055\n",
            "Epoch: 086, AUC: 0.5068, AP: 0.5048\n",
            "Epoch: 087, AUC: 0.5054, AP: 0.5040\n",
            "Epoch: 088, AUC: 0.5051, AP: 0.5039\n",
            "Epoch: 089, AUC: 0.5055, AP: 0.5042\n",
            "Epoch: 090, AUC: 0.5059, AP: 0.5044\n",
            "Epoch: 091, AUC: 0.5076, AP: 0.5054\n",
            "Epoch: 092, AUC: 0.5079, AP: 0.5057\n",
            "Epoch: 093, AUC: 0.5081, AP: 0.5058\n",
            "Epoch: 094, AUC: 0.5091, AP: 0.5065\n",
            "Epoch: 095, AUC: 0.5098, AP: 0.5068\n",
            "Epoch: 096, AUC: 0.5099, AP: 0.5069\n",
            "Epoch: 097, AUC: 0.5100, AP: 0.5069\n",
            "Epoch: 098, AUC: 0.5098, AP: 0.5068\n",
            "Epoch: 099, AUC: 0.5104, AP: 0.5072\n",
            "Epoch: 100, AUC: 0.5111, AP: 0.5076\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t0-lABl1GwX8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}